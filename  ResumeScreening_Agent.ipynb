{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66d3ab5c-d78b-4113-9e59-927719469f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.11.8)\n",
      "Requirement already satisfied: python-docx in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.2.2)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.122.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (2.0.0)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (1.1.6)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (2.3.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (3.11.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (12.0.0)\n",
      "Requirement already satisfied: pydantic<=2.12.4,>=2.11.10 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (2.12.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (6.0.3)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.38.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio-client==2.0.0->gradio) (2025.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.4.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.2.0)\n",
      "Requirement already satisfied: pdfminer.six==20251107 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pdfplumber) (20251107)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pdfplumber) (5.1.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pdfminer.six==20251107->pdfplumber) (46.0.3)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio pdfplumber python-docx scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3b9455f-d342-4166-9878-a4c902bf096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pdfplumber\n",
    "import docx\n",
    "import gradio as gr\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "307669c6-6d31-4ae4-86a1-23b93b502288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_file(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text from PDF, DOCX, or TXT file.\n",
    "    \"\"\"\n",
    "    ext = Path(file_path).suffix.lower()\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        text = \"\"\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text() or \"\"\n",
    "                text += page_text + \"\\n\"\n",
    "        return text\n",
    "\n",
    "    elif ext == \".docx\":\n",
    "        d = docx.Document(file_path)\n",
    "        return \"\\n\".join(p.text for p in d.paragraphs)\n",
    "\n",
    "    elif ext in [\".txt\", \".md\"]:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return f.read()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please upload PDF, DOCX, or TXT.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa7a4a41-d515-446c-b8ce-401749be9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def extract_keywords_from_jd(jd: str):\n",
    "    \"\"\"\n",
    "    Very simple keyword extractor from job description.\n",
    "    You could later replace this with LangChain + GPT for smarter parsing.\n",
    "    \"\"\"\n",
    "    jd_clean = clean_text(jd)\n",
    "    words = re.findall(r\"\\b[a-zA-Z]{3,}\\b\", jd_clean)\n",
    "\n",
    "    stopwords = {\n",
    "        \"with\", \"from\", \"this\", \"that\", \"have\", \"will\", \"your\", \"about\",\n",
    "        \"which\", \"such\", \"their\", \"they\", \"them\", \"like\", \"some\", \"more\",\n",
    "        \"into\", \"able\", \"must\", \"should\", \"role\", \"team\", \"work\", \"tasks\",\n",
    "        \"responsible\", \"responsibilities\", \"requirements\", \"requirement\",\n",
    "        \"skills\", \"skill\", \"experience\", \"years\", \"good\", \"strong\",\n",
    "        \"knowledge\", \"and\", \"for\", \"the\", \"you\", \"our\", \"job\", \"description\"\n",
    "    }\n",
    "\n",
    "    keywords = [w for w in words if w not in stopwords]\n",
    "    return sorted(list(set(keywords)))\n",
    "\n",
    "\n",
    "def tfidf_similarity_scores(jd: str, resume_texts: list):\n",
    "    \"\"\"\n",
    "    Compute TF-IDF based similarity between JD and each resume.\n",
    "    Returns scores in [0, 100].\n",
    "    \"\"\"\n",
    "    corpus = [jd] + resume_texts\n",
    "    corpus_clean = [clean_text(t) for t in corpus]\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus_clean)\n",
    "\n",
    "    jd_vec = tfidf_matrix[0:1]\n",
    "    resume_vecs = tfidf_matrix[1:]\n",
    "\n",
    "    sims = cosine_similarity(jd_vec, resume_vecs)[0]  # 1 x N -> (N,)\n",
    "    scores = [float(s * 100) for s in sims]\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "027a211b-36fe-4cdc-9c4d-99b643b69f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_resumes(job_description: str, files):\n",
    "    if not job_description.strip():\n",
    "        return \"‚ùó Please paste a Job Description first.\"\n",
    "\n",
    "    if not files:\n",
    "        return \"‚ùó Please upload at least one resume (PDF, DOCX, or TXT).\"\n",
    "\n",
    "    # Extract JD keywords (for explanation only)\n",
    "    jd_keywords = extract_keywords_from_jd(job_description)\n",
    "    if not jd_keywords:\n",
    "        jd_keywords = []\n",
    "\n",
    "    resume_texts = []\n",
    "    resume_names = []\n",
    "\n",
    "    for f in files:\n",
    "        try:\n",
    "            text = extract_text_from_file(f.name)\n",
    "            if not text.strip():\n",
    "                continue\n",
    "            resume_texts.append(text)\n",
    "            resume_names.append(Path(f.name).name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {f.name}: {e}\")\n",
    "\n",
    "    if not resume_texts:\n",
    "        return \"‚ö†Ô∏è Could not read any resume text. Make sure files are text-based PDFs or DOCX.\"\n",
    "\n",
    "    # TF-IDF similarity scores\n",
    "    sim_scores = tfidf_similarity_scores(job_description, resume_texts)\n",
    "\n",
    "    results = []\n",
    "    for name, text, sim in zip(resume_names, resume_texts, sim_scores):\n",
    "        # Simple keyword hit count for explanation\n",
    "        resume_clean = clean_text(text)\n",
    "        hits = [kw for kw in jd_keywords if kw in resume_clean]\n",
    "        coverage = round(100 * len(hits) / len(jd_keywords), 2) if jd_keywords else 0.0\n",
    "\n",
    "        # Blend similarity + coverage (you can tweak weights)\n",
    "        final_score = round(0.6 * sim + 0.4 * coverage, 2)\n",
    "\n",
    "        results.append({\n",
    "            \"name\": name,\n",
    "            \"sim_score\": round(sim, 2),\n",
    "            \"kw_coverage\": coverage,\n",
    "            \"final_score\": final_score,\n",
    "            \"matched_keywords\": hits[:20],  # show up to 20\n",
    "        })\n",
    "\n",
    "    # Sort by final_score desc\n",
    "    results_sorted = sorted(results, key=lambda r: r[\"final_score\"], reverse=True)\n",
    "\n",
    "    # Build Markdown report\n",
    "    md = \"# üìä Resume Screening Results\\n\\n\"\n",
    "    md += \"| Rank | Resume | Final Score | JD Similarity | Keyword Coverage |\\n\"\n",
    "    md += \"|------|--------|-------------|---------------|------------------|\\n\"\n",
    "    for i, r in enumerate(results_sorted, start=1):\n",
    "        md += (\n",
    "            f\"| {i} | {r['name']} | {r['final_score']} | \"\n",
    "            f\"{r['sim_score']} | {r['kw_coverage']}% |\\n\"\n",
    "        )\n",
    "\n",
    "    md += \"\\n---\\n\"\n",
    "    md += \"### üîç Per-candidate highlights\\n\"\n",
    "    for i, r in enumerate(results_sorted, start=1):\n",
    "        md += f\"\\n**{i}. {r['name']}**  \\n\"\n",
    "        md += f\"- Final score: `{r['final_score']}`  \\n\"\n",
    "        md += f\"- JD similarity (TF-IDF): `{r['sim_score']}`  \\n\"\n",
    "        md += f\"- Keyword coverage: `{r['kw_coverage']}%`  \\n\"\n",
    "        if r[\"matched_keywords\"]:\n",
    "            md += f\"- Sample matched keywords: `{', '.join(r['matched_keywords'])}`  \\n\"\n",
    "        else:\n",
    "            md += \"- Sample matched keywords: _none detected_  \\n\"\n",
    "\n",
    "    md += (\n",
    "        \"\\n> ‚ÑπÔ∏è This is a local heuristic model (TF-IDF + keywords). \"\n",
    "        \"In a production system, you‚Äôd plug in OpenAI GPT / Claude / Gemini via LangChain \"\n",
    "        \"for deeper semantic scoring and explanations.\"\n",
    "    )\n",
    "\n",
    "    return md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92924358-88ec-44b0-81b9-3cf91e804ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_resumes(job_description: str, files):\n",
    "    if not job_description.strip():\n",
    "        return \"‚ùó Please paste a Job Description first.\"\n",
    "\n",
    "    if not files:\n",
    "        return \"‚ùó Please upload at least one resume (PDF, DOCX, or TXT).\"\n",
    "\n",
    "    # Extract JD keywords (for explanation only)\n",
    "    jd_keywords = extract_keywords_from_jd(job_description)\n",
    "    if not jd_keywords:\n",
    "        jd_keywords = []\n",
    "\n",
    "    resume_texts = []\n",
    "    resume_names = []\n",
    "\n",
    "    for f in files:\n",
    "        try:\n",
    "            text = extract_text_from_file(f.name)\n",
    "            if not text.strip():\n",
    "                continue\n",
    "            resume_texts.append(text)\n",
    "            resume_names.append(Path(f.name).name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {f.name}: {e}\")\n",
    "\n",
    "    if not resume_texts:\n",
    "        return \"‚ö†Ô∏è Could not read any resume text. Make sure files are text-based PDFs or DOCX.\"\n",
    "\n",
    "    # TF-IDF similarity scores\n",
    "    sim_scores = tfidf_similarity_scores(job_description, resume_texts)\n",
    "\n",
    "    results = []\n",
    "    for name, text, sim in zip(resume_names, resume_texts, sim_scores):\n",
    "        # Simple keyword hit count for explanation\n",
    "        resume_clean = clean_text(text)\n",
    "        hits = [kw for kw in jd_keywords if kw in resume_clean]\n",
    "        coverage = round(100 * len(hits) / len(jd_keywords), 2) if jd_keywords else 0.0\n",
    "\n",
    "        # Blend similarity + coverage (you can tweak weights)\n",
    "        final_score = round(0.6 * sim + 0.4 * coverage, 2)\n",
    "\n",
    "        results.append({\n",
    "            \"name\": name,\n",
    "            \"sim_score\": round(sim, 2),\n",
    "            \"kw_coverage\": coverage,\n",
    "            \"final_score\": final_score,\n",
    "            \"matched_keywords\": hits[:20],  # show up to 20\n",
    "        })\n",
    "\n",
    "    # Sort by final_score desc\n",
    "    results_sorted = sorted(results, key=lambda r: r[\"final_score\"], reverse=True)\n",
    "\n",
    "    # Build Markdown report\n",
    "    md = \"# üìä Resume Screening Results\\n\\n\"\n",
    "    md += \"| Rank | Resume | Final Score | JD Similarity | Keyword Coverage |\\n\"\n",
    "    md += \"|------|--------|-------------|---------------|------------------|\\n\"\n",
    "    for i, r in enumerate(results_sorted, start=1):\n",
    "        md += (\n",
    "            f\"| {i} | {r['name']} | {r['final_score']} | \"\n",
    "            f\"{r['sim_score']} | {r['kw_coverage']}% |\\n\"\n",
    "        )\n",
    "\n",
    "    md += \"\\n---\\n\"\n",
    "    md += \"### üîç Per-candidate highlights\\n\"\n",
    "    for i, r in enumerate(results_sorted, start=1):\n",
    "        md += f\"\\n**{i}. {r['name']}**  \\n\"\n",
    "        md += f\"- Final score: `{r['final_score']}`  \\n\"\n",
    "        md += f\"- JD similarity (TF-IDF): `{r['sim_score']}`  \\n\"\n",
    "        md += f\"- Keyword coverage: `{r['kw_coverage']}%`  \\n\"\n",
    "        if r[\"matched_keywords\"]:\n",
    "            md += f\"- Sample matched keywords: `{', '.join(r['matched_keywords'])}`  \\n\"\n",
    "        else:\n",
    "            md += \"- Sample matched keywords: _none detected_  \\n\"\n",
    "\n",
    "    md += (\n",
    "        \"\\n> ‚ÑπÔ∏è This is a local heuristic model (TF-IDF + keywords). \"\n",
    "        \"In a production system, you‚Äôd plug in OpenAI GPT / Claude / Gemini via LangChain \"\n",
    "        \"for deeper semantic scoring and explanations.\"\n",
    "    )\n",
    "\n",
    "    return md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69352a47-4c4b-455a-98f9-4f4ad4663a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_INFO_MD = \"\"\"\n",
    "# üß† ResumeScreening Agent ‚Äì Project Overview\n",
    "\n",
    "This project demonstrates an **AI-powered Resume Screening Agent** that:\n",
    "\n",
    "- Takes a **Job Description (JD)** as input  \n",
    "- Accepts multiple **candidate resumes** (PDF/DOCX/TXT)  \n",
    "- Ranks resumes based on **semantic similarity** + **keyword coverage**  \n",
    "- Shows per-candidate highlights for explanations  \n",
    "\n",
    "---\n",
    "\n",
    "## üîó Target AI Stack (Conceptual Design)\n",
    "\n",
    "Even though this notebook uses local Python + TF-IDF, the project is **designed** to plug into a modern AI stack:\n",
    "\n",
    "### ü§ñ AI Models\n",
    "- **OpenAI GPT** ‚Äì main reasoning engine (fit scoring, explanations)\n",
    "- **Claude** ‚Äì great for long resumes and multi-page JDs\n",
    "- **Gemini** ‚Äì ideal if heavily integrated with Google Workspace\n",
    "\n",
    "### üß∞ Frameworks\n",
    "- **LangChain** ‚Äì tools, prompts, chains (JD parsing, scoring tools)\n",
    "- **CrewAI** ‚Äì multi-agent setup (Screening Agent + Interview Agent, etc.)\n",
    "- **LlamaIndex** ‚Äì building RAG over historical candidate data & job archives\n",
    "\n",
    "### üóÇÔ∏è Vector Databases\n",
    "- **Pinecone** ‚Äì managed, scalable semantic search for resumes & JDs\n",
    "- **ChromaDB / Weaviate** ‚Äì flexible, self-hosted or managed options\n",
    "- **FAISS** ‚Äì fast local vector search for prototypes / small teams\n",
    "\n",
    "### üñ•Ô∏è UI Layer\n",
    "- **Streamlit** ‚Äì internal recruiter dashboard (upload JDs/resumes, view rankings)\n",
    "- **Gradio** ‚Äì quick demo UI (what you're using now)\n",
    "- **HTML/JS** ‚Äì public-facing preview / portfolio website\n",
    "\n",
    "### üßæ Databases\n",
    "- **Firebase / Supabase** ‚Äì auth, logs, recruiter accounts, audit trails\n",
    "- **Notion DB** ‚Äì store candidate pipelines and interview notes as tables\n",
    "- **Google Sheets** ‚Äì simple ATS for smaller teams / college projects\n",
    "\n",
    "### üåê APIs & Integrations\n",
    "- **Google Calendar** ‚Äì automatically schedule interviews for shortlisted candidates\n",
    "- **Calendly** ‚Äì send scheduling links to candidates\n",
    "- **Notion / Sheets** ‚Äì sync ranked candidate lists\n",
    "- **Zapier** ‚Äì trigger Slack/Email notifications from shortlist events\n",
    "- **Shopify** ‚Äì (optional) sync hires or roles for e-commerce teams\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ How to Present This as a Project\n",
    "\n",
    "You can describe your system as:\n",
    "\n",
    "1. **Frontend** ‚Äì Streamlit/Gradio app where HR pastes JD and uploads resumes.  \n",
    "2. **Backend** ‚Äì Python + LangChain/CrewAI orchestrating:\n",
    "   - JD parsing (LLM)\n",
    "   - Resume embedding (vector DB)\n",
    "   - Scoring & ranking (LLM + similarity)\n",
    "3. **Data Layer** ‚Äì Pinecone/ChromaDB/FAISS for embeddings, plus Notion DB / Sheets for pipeline.\n",
    "4. **Automation Layer** ‚Äì Zapier + Google Calendar + Calendly for interview scheduling.\n",
    "\n",
    "This notebook gives you a **working core (ranking logic + UI)** that you can later extend with actual API keys and real LLM calls.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99859813-f6d1-4fe2-ab05-ddec73723ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42d0774e-d1a7-425b-ad45-657cbf093c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def screening_interface(job_description, files):\n",
    "    return rank_resumes(job_description, files)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ü§ñ ResumeScreening Agent ‚Äì Rank Resumes by Job Description\")\n",
    "\n",
    "    with gr.Tab(\"üîç Resume Screening Tool\"):\n",
    "        gr.Markdown(\n",
    "            \"Paste a **Job Description** and upload **multiple resumes**. \"\n",
    "            \"The agent will compute similarity scores and rank them.\"\n",
    "        )\n",
    "        \n",
    "        jd_input = gr.Textbox(\n",
    "            label=\"Job Description\",\n",
    "            lines=10,\n",
    "            placeholder=\"Paste the full JD here...\"\n",
    "        )\n",
    "        \n",
    "        # FIX: Use gr.Files instead of gr.File(multiple=True)\n",
    "        resumes_input = gr.Files(\n",
    "            label=\"Upload resumes (PDF, DOCX, TXT)\",\n",
    "            file_types=[\".pdf\", \".docx\", \".txt\"]\n",
    "        )\n",
    "\n",
    "        output = gr.Markdown()\n",
    "        btn = gr.Button(\"Rank Resumes\")\n",
    "        btn.click(fn=screening_interface, inputs=[jd_input, resumes_input], outputs=output)\n",
    "\n",
    "    with gr.Tab(\"üìö Project & AI Stack\"):\n",
    "        gr.Markdown(PROJECT_INFO_MD)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8e1ec-a677-42a6-bb12-41228d452899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68395f50-16aa-453d-a222-45669959ff0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18b6bf-27b2-48f7-a290-3a97834a0c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45437505-4e4d-46f6-b3a4-c817cb579e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
